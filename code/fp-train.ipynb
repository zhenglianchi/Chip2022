{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install accelerate\n",
    "!pip install seqeval\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"NER_dataset/fp_res.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    dataset=json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset=pd.DataFrame(dataset)\n",
    "train_dataset = Dataset.from_dict(dataset)\n",
    "dataset=DatasetDict({\"train\":train_dataset,\"validation\":train_dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint=\"bert-base-chinese\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            #如果不是None则为其对应的word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitalization_label = [\"O\", \"B-G\", \"I-G\", \"B-D\", \"I-D\", \"B-PD\", \"I-PD\", \"B-PH\", \"I-PH\",\"B-IN\",\"I-IN\",\"B-OUT\",\"I-OUT\",\n",
    "                   \"B-JY\", \"I-JY\", \"B-PR\", \"I-PR\", \"B-SD\", \"I-SD\", \"B-SR\", \"I-SR\", \"B-FR\", \"I-FR\", \"B-L\", \"I-L\", \"B-YL\",\n",
    "                   \"I-YL\", \"B-ZC\", \"I-ZC\", \"B-JC\", \"I-JC\", \"B-HY\", \"I-HY\", \"B-ZL\", \"I-ZL\", \"B-S\", \"I-S\", \"B-WC\", \"I-WC\",\n",
    "                   \"B-WY\", \"I-WY\", \"B-ZY\", \"I-ZY\", \"B-ZCY\", \"I-ZCY\", \"B-YZL\", \"I-YZL\", \"B-CW\", \"I-CW\", \"B-HL\", \"I-HL\",\n",
    "                   \"B-GH\", \"I-GH\", \"B-ELE\", \"I-ELE\", \"B-HJD\", \"I-HJD\", \"B-HJX\", \"I-HJX\", \"B-YTC\", \"I-YTC\", \"B-TC\",\n",
    "                   \"I-TC\", \"B-PX\", \"I-PX\", \"B-PP\", \"I-PP\", \"B-PO\", \"I-PO\", \"B-ELP\", \"I-ELP\", \"B-POO\", \"I-POO\", \"B-PW\",\n",
    "                   \"I-PW\"]\n",
    "# 住院发票标注对应字典\n",
    "token2label = {\"无\": \"O\", \"性别B\": \"B-G\", \"性别I\": \"I-G\", \"入院日期B\":\"B-IN\",\"入院日期I\":\"I-IN\",\"出院日期B\":\"B-OUT\",\"出院日期I\":\"I-OUT\",\n",
    "               \"住院天数B\": \"B-D\", \"住院天数I\": \"I-D\", \"票据代码B\": \"B-PD\", \"票据代码I\": \"I-PD\",\n",
    "               \"票据号码B\": \"B-PH\", \"票据号码I\": \"I-PH\", \"校验码B\": \"B-JY\", \"校验码I\": \"I-JY\", \"开票日期B\": \"B-PR\", \"开票日期I\": \"I-PR\",\n",
    "               \"收款单位B\": \"B-SD\", \"收款单位I\": \"I-SD\", \"收款人B\": \"B-SR\", \"收款人I\": \"I-SR\", \"复核人B\": \"B-FR\", \"复核人I\": \"I-FR\",\n",
    "               \"医疗机构类型B\": \"B-L\", \"医疗机构类型I\": \"I-L\", \"医保类型B\": \"B-YL\", \"医保类型I\": \"I-YL\", \"诊查费B\": \"B-ZC\", \"诊查费I\": \"I-ZC\",\n",
    "               \"检查费B\": \"B-JC\", \"检查费I\": \"I-JC\", \"化验费B\": \"B-HY\", \"化验费I\": \"I-HY\", \"治疗费B\": \"B-ZL\", \"治疗费I\": \"I-ZL\",\n",
    "               \"手术费B\": \"B-S\", \"手术费I\": \"I-S\", \"卫生材料费B\": \"B-WC\", \"卫生材料费I\": \"I-WC\", \"西药费B\": \"B-WY\", \"西药费I\": \"I-WY\",\n",
    "               \"中药饮片B\": \"B-ZY\", \"中药饮片I\": \"I-ZY\", \"中成药费B\": \"B-ZCY\", \"中成药费I\": \"I-ZCY\", \"一般诊疗费B\": \"B-YZL\",\n",
    "               \"一般诊疗费I\": \"I-YZL\",\n",
    "               \"床位费B\": \"B-CW\", \"床位费I\": \"I-CW\", \"护理费B\": \"B-HL\", \"护理费I\": \"I-HL\", \"挂号费B\": \"B-GH\", \"挂号费I\": \"I-GH\",\n",
    "               \"其他收费项目B\": \"B-ELE\", \"其他收费项目I\": \"I-ELE\", \"合计金额（大写）B\": \"B-HJD\", \"合计金额（大写）I\": \"I-HJD\",\n",
    "               \"（小写）B\": \"B-HJX\", \"（小写）I\": \"I-HJX\", \"医保统筹基金支付B\": \"B-YTC\", \"医保统筹基金支付I\": \"I-YTC\", \"统筹支付B\": \"B-TC\",\n",
    "               \"统筹支付I\": \"I-TC\", \"个人现金支付B\": \"B-PX\", \"个人现金支付I\": \"I-PX\", \"个人账户支付B\": \"B-PP\", \"个人账户支付I\": \"I-PP\",\n",
    "               \"个人自付B\": \"B-PO\", \"个人自付I\": \"I-PO\", \"其他支付B\": \"B-ELP\", \"其他支付I\": \"I-ELP\", \"自付一B\": \"B-POO\", \"自付一I\": \"I-POO\",\n",
    "               \"自付二B\": \"B-PW\", \"自付二I\": \"I-PW\"\n",
    "               }\n",
    "\n",
    "id2label = {str(i): label for i, label in enumerate(hospitalization_label)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "'''客户信息字段（属性名共 4个）：性别-G、入院日期-IN、出院日期-OUT、住院天数-D\n",
    "   发票信息字段（属性名共 7个）：票据代码-PD、票据号码-PH、校验码-JY、开票日期-PR、收款单位-SD、收款人-SR、复核人-FR\n",
    "   医保信息字段（属性名共 2个）：医疗机构类型-L、医保类型-YL\n",
    "   项目信息字段（属性名共 14个）：诊查费-ZC、检查费-JC、化验费-HY、治疗费-ZL、手术费-S、卫生材料费-WC、西药费-WY、中药饮片-ZY、中成药费-ZCY、一般诊疗费-YZL、床位费-CW、护理费-HL、挂号费-GH、其他收费项目-ELE\n",
    "   支付信息字段（属性名共 10个）：合计金额（大写）-HJD、（小写）-HJX、医保统筹基金支付-YTC、统筹支付-TC、个人现金支付-PX、个人账户支付-PP、个人自付-PO、其他支付-ELP、自付一-POO、自付二-PW'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 96\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[hospitalization_label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [hospitalization_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "        \n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"fp-ner\")\n",
    "model.push_to_hub(\"fp-ner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hugging-face')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c79dcc4c2e7ae053d2da844ff53b34f816b04fdae7b78150cd6460ee1a480f94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
